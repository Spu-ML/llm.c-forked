{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36714b9c-a417-4332-ab79-c29184e3140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_checkpoint import get_state\n",
    "from train_gpt2 import GPTConfig, GPT, write_model\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc1000-f0f5-45dd-8c3b-30e6361947ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = GPTConfig(n_embd=16,n_layer=2,n_head=4,block_size=128,vocab_size=50257)\n",
    "# model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d1cb6d3-0271-4253-a97a-3197372f027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haris/miniconda3/envs/nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = GPT.from_pretrained('gpt2')\n",
    "model_hf = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cfefab9-0e27-4c66-9abb-60bd1d0902e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded vocab size from 50257 to 50304\n",
      "wrote gpt2.bin\n"
     ]
    }
   ],
   "source": [
    "write_model(model, 'gpt2.bin', dtype='bfloat16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b3ee140-1804-4bce-bf48-21612ad96bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gpt2.bin'\n",
    "sd,config = get_state(filename, return_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b94a0a3d-e77c-4f17-b52e-4e1bfc8d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_config = GPT2Config(\n",
    "    vocab_size=config.vocab_size,\n",
    "    n_positions=config.block_size,\n",
    "    # n_ctx=config.block_size,\n",
    "    n_embd=config.n_embd,\n",
    "    n_layer=config.n_layer,\n",
    "    n_head=config.n_head,\n",
    ")\n",
    "model_hf_sd = GPT2LMHeadModel(hf_config)\n",
    "\n",
    "sd_hf = model_hf_sd.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3473c867-de15-41c9-92a3-4e22ed390033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "sd_keys_hf = sd_hf.keys()\n",
    "sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "556e36be-d847-44bf-93a5-7818548d3a8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n",
      "torch.Size([2304, 768])\n",
      "torch.Size([768, 2304])\n",
      "\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "\n",
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n",
      "\n",
      "torch.Size([768, 3072])\n",
      "torch.Size([3072, 768])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in sd_keys_hf:\n",
    "    if any(k.endswith(w) for w in transposed):\n",
    "        # special treatment for the Conv1D weights we need to transpose\n",
    "        print(sd[k].shape)\n",
    "        assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "        with torch.no_grad():\n",
    "            sd[k]=sd[k].t()\n",
    "        print(sd[k].shape)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24d3714a-7be0-4be5-81d5-a2ae6bd28906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = model_hf_sd.load_state_dict(sd,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "996837c3-7bfe-43c0-a195-7f6de3104c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['transformer.h.0.attn.bias', 'transformer.h.1.attn.bias', 'transformer.h.2.attn.bias', 'transformer.h.3.attn.bias', 'transformer.h.4.attn.bias', 'transformer.h.5.attn.bias', 'transformer.h.6.attn.bias', 'transformer.h.7.attn.bias', 'transformer.h.8.attn.bias', 'transformer.h.9.attn.bias', 'transformer.h.10.attn.bias', 'transformer.h.11.attn.bias'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc3f5e0e-42c6-4133-bf13-00d538bbea96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.h.0.attn.bias',\n",
       " 'transformer.h.1.attn.bias',\n",
       " 'transformer.h.2.attn.bias',\n",
       " 'transformer.h.3.attn.bias',\n",
       " 'transformer.h.4.attn.bias',\n",
       " 'transformer.h.5.attn.bias',\n",
       " 'transformer.h.6.attn.bias',\n",
       " 'transformer.h.7.attn.bias',\n",
       " 'transformer.h.8.attn.bias',\n",
       " 'transformer.h.9.attn.bias',\n",
       " 'transformer.h.10.attn.bias',\n",
       " 'transformer.h.11.attn.bias']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.unexpected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32374afa-87e0-420f-a634-600f0b539422",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in m.unexpected_keys:\n",
    "    assert k.endswith('.attn.masked_bias') or k.endswith('.attn.bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f5b3b-733f-4995-a709-4fcdf372e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(sd_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5e1ee-591e-4d74-bcb6-f41841d980d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
